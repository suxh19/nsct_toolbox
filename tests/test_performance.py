"""
æ€§èƒ½æµ‹è¯• - å¯¹æ¯” nsct_python (NumPy CPU) å’Œ nsct_torch (PyTorch CPU/GPU) çš„æ€§èƒ½
"""

import pytest
import numpy as np
import torch
import time
import sys
from pathlib import Path
from typing import Dict, List, Callable

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from nsct_python import utils as np_utils
from nsct_torch import utils as torch_utils


class TestPerformance:
    """æ€§èƒ½æµ‹è¯•ç±»"""
    
    @pytest.fixture
    def devices(self):
        """è·å–å¯ç”¨çš„è®¾å¤‡åˆ—è¡¨"""
        devices = ['cpu']
        if torch.cuda.is_available():
            devices.append('cuda')
        return devices
    
    @pytest.fixture
    def test_sizes(self):
        """å®šä¹‰ä¸åŒçš„æµ‹è¯•å°ºå¯¸"""
        return {
            'small': (32, 32),
            'medium': (128, 128),
            'large': (256, 256),
            'xlarge': (512, 512)
        }
    
    def time_function(self, func: Callable, *args, warmup: int = 3, iterations: int = 10, **kwargs) -> Dict:
        """
        æµ‹é‡å‡½æ•°æ‰§è¡Œæ—¶é—´
        
        Args:
            func: è¦æµ‹è¯•çš„å‡½æ•°
            *args: å‡½æ•°å‚æ•°
            warmup: é¢„çƒ­æ¬¡æ•°
            iterations: æµ‹è¯•è¿­ä»£æ¬¡æ•°
            **kwargs: å‡½æ•°å…³é”®å­—å‚æ•°
            
        Returns:
            åŒ…å«æ—¶é—´ç»Ÿè®¡çš„å­—å…¸
        """
        # é¢„çƒ­
        for _ in range(warmup):
            _ = func(*args, **kwargs)
        
        # å¦‚æœæ˜¯ CUDAï¼ŒåŒæ­¥
        if len(args) > 0 and isinstance(args[0], torch.Tensor) and args[0].is_cuda:
            torch.cuda.synchronize()
        
        # æµ‹é‡æ—¶é—´
        times = []
        for _ in range(iterations):
            start = time.perf_counter()
            result = func(*args, **kwargs)
            
            # å¦‚æœæ˜¯ CUDAï¼ŒåŒæ­¥
            if isinstance(result, torch.Tensor) and result.is_cuda:
                torch.cuda.synchronize()
            
            end = time.perf_counter()
            times.append((end - start) * 1000)  # è½¬æ¢ä¸ºæ¯«ç§’
        
        return {
            'mean': np.mean(times),
            'std': np.std(times),
            'min': np.min(times),
            'max': np.max(times),
            'times': times
        }
    
    def print_performance_comparison(self, name: str, size: tuple, results: Dict):
        """æ‰“å°æ€§èƒ½å¯¹æ¯”ç»“æœ"""
        print(f"\n{'='*80}")
        print(f"ğŸ“Š {name} æ€§èƒ½æµ‹è¯• - è¾“å…¥å¤§å°: {size}")
        print(f"{'='*80}")
        
        # æ”¶é›†æ‰€æœ‰ç»“æœ
        all_results = []
        for device, stats in results.items():
            all_results.append({
                'device': device,
                'mean': stats['mean'],
                'std': stats['std']
            })
        
        # æŒ‰å¹³å‡æ—¶é—´æ’åº
        all_results.sort(key=lambda x: x['mean'])
        
        # æ‰¾åˆ°æœ€å¿«çš„
        fastest = all_results[0]['mean']
        
        print(f"\n{'è®¾å¤‡':<15} {'å¹³å‡æ—¶é—´ (ms)':<20} {'æ ‡å‡†å·® (ms)':<20} {'åŠ é€Ÿæ¯”':<15}")
        print(f"{'-'*80}")
        
        for result in all_results:
            speedup = fastest / result['mean']
            device_name = result['device'].upper() if result['device'] != 'numpy_cpu' else 'NumPy (CPU)'
            if result['device'] == 'cpu':
                device_name = 'PyTorch (CPU)'
            elif result['device'] == 'cuda':
                device_name = 'PyTorch (CUDA)'
            
            print(f"{device_name:<15} {result['mean']:<20.4f} {result['std']:<20.4f} {speedup:<15.2f}x")
        
        print(f"\nğŸ† æœ€å¿«: {all_results[0]['device'].upper()}")
        if len(all_results) > 1:
            slowest_speedup = all_results[-1]['mean'] / fastest
            print(f"âš¡ ç›¸æ¯”æœ€æ…¢åŠ é€Ÿ: {slowest_speedup:.2f}x")
    
    # ==================== extend2 æ€§èƒ½æµ‹è¯• ====================
    
    def test_performance_extend2(self, devices, test_sizes):
        """æµ‹è¯• extend2 å‡½æ•°çš„æ€§èƒ½"""
        for size_name, size in test_sizes.items():
            print(f"\n\n{'#'*80}")
            print(f"æµ‹è¯•å°ºå¯¸: {size_name.upper()} {size}")
            print(f"{'#'*80}")
            
            # å‡†å¤‡æ•°æ®
            x_np = np.random.randn(*size).astype(np.float32)
            
            results = {}
            
            # NumPy CPU ç‰ˆæœ¬
            print("\nğŸ”„ æµ‹è¯• NumPy (CPU) ç‰ˆæœ¬...")
            results['numpy_cpu'] = self.time_function(
                np_utils.extend2, x_np, 2, 2, 2, 2, 'per'
            )
            
            # PyTorch ç‰ˆæœ¬
            for device in devices:
                print(f"\nğŸ”„ æµ‹è¯• PyTorch ({device.upper()}) ç‰ˆæœ¬...")
                x_torch = torch.from_numpy(x_np).to(device)
                results[device] = self.time_function(
                    torch_utils.extend2, x_torch, 2, 2, 2, 2, 'per'
                )
            
            # æ‰“å°å¯¹æ¯”ç»“æœ
            self.print_performance_comparison('extend2', size, results)
    
    # ==================== symext æ€§èƒ½æµ‹è¯• ====================
    
    def test_performance_symext(self, devices, test_sizes):
        """æµ‹è¯• symext å‡½æ•°çš„æ€§èƒ½"""
        for size_name, size in test_sizes.items():
            print(f"\n\n{'#'*80}")
            print(f"æµ‹è¯•å°ºå¯¸: {size_name.upper()} {size}")
            print(f"{'#'*80}")
            
            # å‡†å¤‡æ•°æ®
            x_np = np.random.randn(*size).astype(np.float32)
            h_np = np.ones((5, 5), dtype=np.float32)
            shift = [2, 2]
            
            results = {}
            
            # NumPy CPU ç‰ˆæœ¬
            print("\nğŸ”„ æµ‹è¯• NumPy (CPU) ç‰ˆæœ¬...")
            results['numpy_cpu'] = self.time_function(
                np_utils.symext, x_np, h_np, shift
            )
            
            # PyTorch ç‰ˆæœ¬
            for device in devices:
                print(f"\nğŸ”„ æµ‹è¯• PyTorch ({device.upper()}) ç‰ˆæœ¬...")
                x_torch = torch.from_numpy(x_np).to(device)
                h_torch = torch.from_numpy(h_np).to(device)
                results[device] = self.time_function(
                    torch_utils.symext, x_torch, h_torch, shift
                )
            
            # æ‰“å°å¯¹æ¯”ç»“æœ
            self.print_performance_comparison('symext', size, results)
    
    # ==================== upsample2df æ€§èƒ½æµ‹è¯• ====================
    
    def test_performance_upsample2df(self, devices):
        """æµ‹è¯• upsample2df å‡½æ•°çš„æ€§èƒ½"""
        test_sizes = {
            'small': (8, 8),
            'medium': (32, 32),
            'large': (64, 64),
            'xlarge': (128, 128)
        }
        
        for size_name, size in test_sizes.items():
            print(f"\n\n{'#'*80}")
            print(f"æµ‹è¯•å°ºå¯¸: {size_name.upper()} {size}")
            print(f"{'#'*80}")
            
            # å‡†å¤‡æ•°æ®
            h_np = np.random.randn(*size).astype(np.float32)
            power = 2
            
            results = {}
            
            # NumPy CPU ç‰ˆæœ¬
            print("\nğŸ”„ æµ‹è¯• NumPy (CPU) ç‰ˆæœ¬...")
            results['numpy_cpu'] = self.time_function(
                np_utils.upsample2df, h_np, power
            )
            
            # PyTorch ç‰ˆæœ¬
            for device in devices:
                print(f"\nğŸ”„ æµ‹è¯• PyTorch ({device.upper()}) ç‰ˆæœ¬...")
                h_torch = torch.from_numpy(h_np).to(device)
                results[device] = self.time_function(
                    torch_utils.upsample2df, h_torch, power
                )
            
            # æ‰“å°å¯¹æ¯”ç»“æœ
            self.print_performance_comparison('upsample2df', size, results)
    
    # ==================== modulate2 æ€§èƒ½æµ‹è¯• ====================
    
    def test_performance_modulate2(self, devices, test_sizes):
        """æµ‹è¯• modulate2 å‡½æ•°çš„æ€§èƒ½"""
        for size_name, size in test_sizes.items():
            print(f"\n\n{'#'*80}")
            print(f"æµ‹è¯•å°ºå¯¸: {size_name.upper()} {size}")
            print(f"{'#'*80}")
            
            # å‡†å¤‡æ•°æ®
            x_np = np.random.randn(*size).astype(np.float32)
            
            results = {}
            
            # NumPy CPU ç‰ˆæœ¬
            print("\nğŸ”„ æµ‹è¯• NumPy (CPU) ç‰ˆæœ¬...")
            results['numpy_cpu'] = self.time_function(
                np_utils.modulate2, x_np, 'b'
            )
            
            # PyTorch ç‰ˆæœ¬
            for device in devices:
                print(f"\nğŸ”„ æµ‹è¯• PyTorch ({device.upper()}) ç‰ˆæœ¬...")
                x_torch = torch.from_numpy(x_np).to(device)
                results[device] = self.time_function(
                    torch_utils.modulate2, x_torch, 'b'
                )
            
            # æ‰“å°å¯¹æ¯”ç»“æœ
            self.print_performance_comparison('modulate2', size, results)
    
    # ==================== resampz æ€§èƒ½æµ‹è¯• ====================
    
    def test_performance_resampz(self, devices, test_sizes):
        """æµ‹è¯• resampz å‡½æ•°çš„æ€§èƒ½"""
        for size_name, size in test_sizes.items():
            print(f"\n\n{'#'*80}")
            print(f"æµ‹è¯•å°ºå¯¸: {size_name.upper()} {size}")
            print(f"{'#'*80}")
            
            # å‡†å¤‡æ•°æ®
            x_np = np.random.randn(*size).astype(np.float32)
            
            results = {}
            
            # NumPy CPU ç‰ˆæœ¬
            print("\nğŸ”„ æµ‹è¯• NumPy (CPU) ç‰ˆæœ¬...")
            results['numpy_cpu'] = self.time_function(
                np_utils.resampz, x_np, 1, 1
            )
            
            # PyTorch ç‰ˆæœ¬
            for device in devices:
                print(f"\nğŸ”„ æµ‹è¯• PyTorch ({device.upper()}) ç‰ˆæœ¬...")
                x_torch = torch.from_numpy(x_np).to(device)
                results[device] = self.time_function(
                    torch_utils.resampz, x_torch, 1, 1
                )
            
            # æ‰“å°å¯¹æ¯”ç»“æœ
            self.print_performance_comparison('resampz', size, results)
    
    # ==================== qupz æ€§èƒ½æµ‹è¯• ====================
    
    def test_performance_qupz(self, devices, test_sizes):
        """æµ‹è¯• qupz å‡½æ•°çš„æ€§èƒ½"""
        for size_name, size in test_sizes.items():
            print(f"\n\n{'#'*80}")
            print(f"æµ‹è¯•å°ºå¯¸: {size_name.upper()} {size}")
            print(f"{'#'*80}")
            
            # å‡†å¤‡æ•°æ®
            x_np = np.random.randn(*size).astype(np.float32)
            
            results = {}
            
            # NumPy CPU ç‰ˆæœ¬
            print("\nğŸ”„ æµ‹è¯• NumPy (CPU) ç‰ˆæœ¬...")
            results['numpy_cpu'] = self.time_function(
                np_utils.qupz, x_np, 1
            )
            
            # PyTorch ç‰ˆæœ¬
            for device in devices:
                print(f"\nğŸ”„ æµ‹è¯• PyTorch ({device.upper()}) ç‰ˆæœ¬...")
                x_torch = torch.from_numpy(x_np).to(device)
                results[device] = self.time_function(
                    torch_utils.qupz, x_torch, 1
                )
            
            # æ‰“å°å¯¹æ¯”ç»“æœ
            self.print_performance_comparison('qupz', size, results)
    
    # ==================== ç»¼åˆæ€§èƒ½æŠ¥å‘Š ====================
    
    def test_performance_summary(self, devices):
        """ç”Ÿæˆç»¼åˆæ€§èƒ½æŠ¥å‘Š"""
        print(f"\n\n{'='*80}")
        print("ğŸ“Š ç»¼åˆæ€§èƒ½æµ‹è¯•æ€»ç»“")
        print(f"{'='*80}")
        
        print(f"\nå¯ç”¨è®¾å¤‡: {', '.join([d.upper() for d in devices])}")
        
        if 'cuda' in devices:
            print(f"CUDA è®¾å¤‡: {torch.cuda.get_device_name(0)}")
            print(f"CUDA ç‰ˆæœ¬: {torch.version.cuda}")
        
        print(f"PyTorch ç‰ˆæœ¬: {torch.__version__}")
        print(f"NumPy ç‰ˆæœ¬: {np.__version__}")
        
        print("\n" + "="*80)
        print("âœ… æ€§èƒ½æµ‹è¯•å®Œæˆï¼")
        print("="*80)
        
        print("\nğŸ’¡ æç¤º:")
        print("  - CPU ç‰ˆæœ¬é€‚åˆå°è§„æ¨¡æ•°æ®å’Œè°ƒè¯•")
        print("  - GPU ç‰ˆæœ¬åœ¨å¤§è§„æ¨¡æ•°æ®ä¸Šæœ‰æ˜¾è‘—ä¼˜åŠ¿")
        print("  - æ•°æ®ä¼ è¾“å¼€é”€åœ¨å°æ•°æ®ä¸Šå¯èƒ½å½±å“ GPU æ€§èƒ½")


if __name__ == '__main__':
    # å¯ä»¥ç›´æ¥è¿è¡Œæ­¤æ–‡ä»¶è¿›è¡Œæ€§èƒ½æµ‹è¯•
    # è¿è¡Œæ‰€æœ‰æ€§èƒ½æµ‹è¯•
    pytest.main([__file__, '-v', '-s'])
    
    # æˆ–è¿è¡Œç‰¹å®šæµ‹è¯•
    # pytest.main([__file__, '-v', '-s', '-k', 'extend2'])
